cpu-bind=MASK - gpu19-1.drl, task  0  0 [2065167]: mask 0x1 set
Fri May 10 10:38:58 PM EDT 2024
Running my job on gpu19-1.drl
/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.5) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.
  warnings.warn(
/ - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / SETTING DEVICE AS cuda
Opening dataset in read-only mode as you don't have write permissions.
This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art

- \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / hub://activeloop/wiki-art loaded successfully.

/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/integrations/pytorch/common.py:137: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.
  warnings.warn(
Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]Please wait, filling up the shuffle buffer with samples.:   1%|          | 13.7M/2.00G [00:02<05:22, 6.62MB/s]Please wait, filling up the shuffle buffer with samples.:   7%|▋         | 144M/2.00G [00:04<00:45, 43.7MB/s] Please wait, filling up the shuffle buffer with samples.:  10%|▉         | 199M/2.00G [00:06<00:58, 33.3MB/s]Please wait, filling up the shuffle buffer with samples.:  17%|█▋        | 340M/2.00G [00:07<00:27, 65.7MB/s]Please wait, filling up the shuffle buffer with samples.:  22%|██▏       | 451M/2.00G [00:07<00:16, 103MB/s] Please wait, filling up the shuffle buffer with samples.:  37%|███▋      | 752M/2.00G [00:07<00:05, 244MB/s]Please wait, filling up the shuffle buffer with samples.:  46%|████▋     | 947M/2.00G [00:08<00:05, 193MB/s]Please wait, filling up the shuffle buffer with samples.:  68%|██████▊   | 1.36G/2.00G [00:08<00:01, 393MB/s]Please wait, filling up the shuffle buffer with samples.:  79%|███████▊  | 1.57G/2.00G [00:09<00:01, 407MB/s]Please wait, filling up the shuffle buffer with samples.:  85%|████████▌ | 1.70G/2.00G [00:10<00:01, 301MB/s]Please wait, filling up the shuffle buffer with samples.:  90%|████████▉ | 1.80G/2.00G [00:10<00:00, 287MB/s]Please wait, filling up the shuffle buffer with samples.:  94%|█████████▍| 1.88G/2.00G [00:10<00:00, 319MB/s]Please wait, filling up the shuffle buffer with samples.:  98%|█████████▊| 1.95G/2.00G [00:11<00:00, 269MB/s]Please wait, filling up the shuffle buffer with samples.: 100%|█████████▉| 2.00G/2.00G [00:11<00:00, 187MB/s]
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 64, 64])) that is different to the input size (torch.Size([32, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 128, 128])) that is different to the input size (torch.Size([32, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([32, 128, 128, 128])) that is different to the input size (torch.Size([1, 128, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 256, 256])) that is different to the input size (torch.Size([32, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 438.00 MiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 866.00 MiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Shuffle buffer filling is complete.
Building the style transfer model..
Optimizing..
0
20
40
run [50]:
Style Loss : 2.375726 Content Loss: 4.403043

60
80
run [100]:
Style Loss : 1.878935 Content Loss: 4.256140

100
120
140
run [150]:
Style Loss : 1.971815 Content Loss: 4.788854

160
180
run [200]:
Style Loss : 3.047793 Content Loss: 7.277585

200
220
240
run [250]:
Style Loss : 1.971950 Content Loss: 4.786827

260
280
run [300]:
Style Loss : 2.206903 Content Loss: 5.475569

300
Optimizing..
run [25]:
Loss : 0.016494, Floss: 0.016493, Mloss 0.000002

run [50]:
Loss : 0.006297, Floss: 0.006295, Mloss 0.000003

run [75]:
Loss : 0.003468, Floss: 0.003465, Mloss 0.000003

run [100]:
Loss : 0.002259, Floss: 0.002255, Mloss 0.000004

run [125]:
Loss : 0.001562, Floss: 0.001558, Mloss 0.000004

run [150]:
Loss : 0.001154, Floss: 0.001149, Mloss 0.000005

run [175]:
Loss : 0.000884, Floss: 0.000879, Mloss 0.000005

run [200]:
Loss : 0.000707, Floss: 0.000702, Mloss 0.000005

run [225]:
Loss : 0.000583, Floss: 0.000578, Mloss 0.000006

run [250]:
Loss : 0.000490, Floss: 0.000484, Mloss 0.000006

run [275]:
Loss : 0.000415, Floss: 0.000409, Mloss 0.000006

run [300]:
Loss : 0.000357, Floss: 0.000350, Mloss 0.000006

run [325]:
Loss : 0.000310, Floss: 0.000304, Mloss 0.000007

run [350]:
Loss : 0.000274, Floss: 0.000267, Mloss 0.000007

run [375]:
Loss : 0.000246, Floss: 0.000239, Mloss 0.000007

run [400]:
Loss : 0.000222, Floss: 0.000215, Mloss 0.000007

(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
(256, 256, 3)
Building the style transfer model..
Optimizing..
0
20
40
run [50]:
Style Loss : 2.091851 Content Loss: 4.559021

60
80
Traceback (most recent call last):
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 350, in <module>
    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 239, in run_style_transfer
    optimizer.step(closure)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 445, in step
    loss = float(closure())
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 228, in closure
    loss.backward()
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/_tensor.py", line 516, in backward
    return handle_torch_function(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/overrides.py", line 1619, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py", line 78, in __torch_function__
    return func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 
