cpu-bind=MASK - gpu19-1.drl, task  0  0 [2058179]: mask 0x1 set
Fri May 10 10:27:52 PM EDT 2024
Running my job on gpu19-1.drl
/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.5) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.
  warnings.warn(
/ - \ | / - \ SETTING DEVICE AS cuda
Opening dataset in read-only mode as you don't have write permissions.
This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art

| / - \ | / - \ | / - \ hub://activeloop/wiki-art loaded successfully.

/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/integrations/pytorch/common.py:137: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.
  warnings.warn(
Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]Please wait, filling up the shuffle buffer with samples.:   0%|          | 1.66M/2.00G [00:01<29:59, 1.19MB/s]Please wait, filling up the shuffle buffer with samples.:   1%|▏         | 29.3M/2.00G [00:03<03:16, 10.8MB/s]Please wait, filling up the shuffle buffer with samples.:  13%|█▎        | 256M/2.00G [00:03<00:14, 125MB/s]  Please wait, filling up the shuffle buffer with samples.:  18%|█▊        | 372M/2.00G [00:06<00:24, 70.5MB/s]Please wait, filling up the shuffle buffer with samples.:  32%|███▏      | 651M/2.00G [00:06<00:09, 162MB/s] Please wait, filling up the shuffle buffer with samples.:  39%|███▊      | 790M/2.00G [00:06<00:06, 216MB/s]Please wait, filling up the shuffle buffer with samples.:  49%|████▉     | 999M/2.00G [00:06<00:03, 331MB/s]Please wait, filling up the shuffle buffer with samples.:  58%|█████▊    | 1.16G/2.00G [00:08<00:04, 218MB/s]Please wait, filling up the shuffle buffer with samples.:  65%|██████▍   | 1.29G/2.00G [00:09<00:04, 186MB/s]Please wait, filling up the shuffle buffer with samples.:  80%|███████▉  | 1.60G/2.00G [00:09<00:01, 320MB/s]Please wait, filling up the shuffle buffer with samples.:  88%|████████▊ | 1.76G/2.00G [00:10<00:00, 285MB/s]Please wait, filling up the shuffle buffer with samples.:  98%|█████████▊| 1.96G/2.00G [00:10<00:00, 388MB/s]Please wait, filling up the shuffle buffer with samples.: 100%|█████████▉| 1.99G/2.00G [00:11<00:00, 192MB/s]
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 64, 64])) that is different to the input size (torch.Size([8, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 128, 128])) that is different to the input size (torch.Size([8, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([8, 128, 256, 256])) that is different to the input size (torch.Size([1, 128, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 256, 256])) that is different to the input size (torch.Size([8, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Shuffle buffer filling is complete.
Building the style transfer model..
Optimizing..
0
20
40
run [50]:
Style Loss : 1.621637 Content Loss: 2.705305

60
80
run [100]:
Style Loss : 1.285820 Content Loss: 2.657412

100
120
140
run [150]:
Style Loss : 1.265801 Content Loss: 2.802912

160
180
run [200]:
Style Loss : 61197.105469 Content Loss: 339.784210

200
220
240
run [250]:
Style Loss : 13.167116 Content Loss: 15.024469

260
280
run [300]:
Style Loss : 12.491239 Content Loss: 8.528419

300
Optimizing..
run [25]:
Loss : 0.004489, Floss: 0.004488, Mloss 0.000001

run [50]:
Loss : 0.001465, Floss: 0.001464, Mloss 0.000001

run [75]:
Loss : 0.000722, Floss: 0.000720, Mloss 0.000002

run [100]:
Loss : 0.000422, Floss: 0.000420, Mloss 0.000002

run [125]:
Loss : 0.000273, Floss: 0.000271, Mloss 0.000002

run [150]:
Loss : 0.000189, Floss: 0.000187, Mloss 0.000002

run [175]:
Loss : 0.000140, Floss: 0.000137, Mloss 0.000002

run [200]:
Loss : 0.000108, Floss: 0.000105, Mloss 0.000003

run [225]:
Loss : 0.000085, Floss: 0.000083, Mloss 0.000003

run [250]:
Loss : 0.000069, Floss: 0.000066, Mloss 0.000003

run [275]:
Loss : 0.000057, Floss: 0.000054, Mloss 0.000003

run [300]:
Loss : 0.000048, Floss: 0.000045, Mloss 0.000003

run [325]:
Loss : 0.000041, Floss: 0.000038, Mloss 0.000003

run [350]:
Loss : 0.000036, Floss: 0.000033, Mloss 0.000003

run [375]:
Loss : 0.000031, Floss: 0.000028, Mloss 0.000003

run [400]:
Loss : 0.000028, Floss: 0.000025, Mloss 0.000003

(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
(512, 512, 3)
Building the style transfer model..
Optimizing..
0
20
40
run [50]:
Style Loss : 1.780337 Content Loss: 3.230306

60
80
Traceback (most recent call last):
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 350, in <module>
    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 239, in run_style_transfer
    optimizer.step(closure)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 445, in step
    loss = float(closure())
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 228, in closure
    loss.backward()
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/_tensor.py", line 516, in backward
    return handle_torch_function(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/overrides.py", line 1619, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py", line 78, in __torch_function__
    return func(*args, **kwargs)
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 
