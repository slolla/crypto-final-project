cpu-bind=MASK - gpu19-1.drl, task  0  0 [2069291]: mask 0x1 set
Fri May 10 10:46:02 PM EDT 2024
Running my job on gpu19-1.drl
/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.5) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.
  warnings.warn(
/ - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ SETTING DEVICE AS cuda
Opening dataset in read-only mode as you don't have write permissions.
This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art

| / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - hub://activeloop/wiki-art loaded successfully.

/tmp/home/amini/.local/lib/python3.10/site-packages/deeplake/integrations/pytorch/common.py:137: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.
  warnings.warn(
Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]Please wait, filling up the shuffle buffer with samples.:   1%|          | 11.4M/2.00G [00:02<08:36, 4.14MB/s]Please wait, filling up the shuffle buffer with samples.:   7%|▋         | 143M/2.00G [00:11<02:26, 13.6MB/s] Please wait, filling up the shuffle buffer with samples.:  23%|██▎       | 465M/2.00G [00:12<00:33, 49.5MB/s]Please wait, filling up the shuffle buffer with samples.:  42%|████▏     | 852M/2.00G [00:13<00:11, 113MB/s] Please wait, filling up the shuffle buffer with samples.:  58%|█████▊    | 1.15G/2.00G [00:13<00:04, 184MB/s]Please wait, filling up the shuffle buffer with samples.:  73%|███████▎  | 1.46G/2.00G [00:13<00:02, 272MB/s]Please wait, filling up the shuffle buffer with samples.:  83%|████████▎ | 1.67G/2.00G [00:13<00:01, 350MB/s]Please wait, filling up the shuffle buffer with samples.:  99%|█████████▉| 1.98G/2.00G [00:13<00:00, 157MB/s]
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 64, 64])) that is different to the input size (torch.Size([32, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 128, 128])) that is different to the input size (torch.Size([32, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([32, 128, 128, 128])) that is different to the input size (torch.Size([1, 128, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Using a target size (torch.Size([1, 256, 256])) that is different to the input size (torch.Size([32, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/tmp/home/amini/.local/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return func(*args, **kwargs)
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/tmp/home/amini/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Shuffle buffer filling is complete.
Building the style transfer model..
Optimizing..
0
20
40
run [50]:
Style Loss : 2.179263 Content Loss: 4.459197

60
80
run [100]:
Style Loss : 1.807627 Content Loss: 4.344733

100
120
140
run [150]:
Style Loss : 1.961174 Content Loss: 4.667794

160
180
run [200]:
Style Loss : 9.522440 Content Loss: 7.277292

200
220
240
run [250]:
Style Loss : 2.538005 Content Loss: 6.163198

260
280
run [300]:
Style Loss : 4.961978 Content Loss: 6.641469

300
Optimizing..
run [25]:
Loss : 0.020643, Floss: 0.020641, Mloss 0.000002

run [50]:
Loss : 0.007740, Floss: 0.007736, Mloss 0.000004

run [75]:
Loss : 0.004363, Floss: 0.004358, Mloss 0.000005

run [100]:
Loss : 0.002851, Floss: 0.002845, Mloss 0.000006

run [125]:
Loss : 0.002022, Floss: 0.002015, Mloss 0.000006

run [150]:
Loss : 0.001520, Floss: 0.001513, Mloss 0.000007

run [175]:
Loss : 0.001198, Floss: 0.001190, Mloss 0.000008

run [200]:
Loss : 0.000976, Floss: 0.000968, Mloss 0.000008

run [225]:
Loss : 0.000807, Floss: 0.000798, Mloss 0.000009

run [250]:
Loss : 0.000684, Floss: 0.000675, Mloss 0.000009

run [275]:
Loss : 0.000592, Floss: 0.000583, Mloss 0.000010

run [300]:
Loss : 0.000518, Floss: 0.000508, Mloss 0.000010

run [325]:
Loss : 0.000457, Floss: 0.000446, Mloss 0.000010

run [350]:
Loss : 0.000406, Floss: 0.000395, Mloss 0.000011

run [375]:
Loss : 0.000365, Floss: 0.000354, Mloss 0.000011

run [400]:
Loss : 0.000329, Floss: 0.000318, Mloss 0.000012

saved decrypt_dataset/banksy_0_encrypted
saved decrypt_dataset/banksy_1_encrypted
saved decrypt_dataset/banksy_2_encrypted
saved decrypt_dataset/banksy_3_encrypted
saved decrypt_dataset/banksy_4_encrypted
saved decrypt_dataset/banksy_5_encrypted
saved decrypt_dataset/banksy_6_encrypted
saved decrypt_dataset/banksy_7_encrypted
saved decrypt_dataset/banksy_8_encrypted
saved decrypt_dataset/banksy_9_encrypted
saved decrypt_dataset/banksy_10_encrypted
saved decrypt_dataset/banksy_11_encrypted
saved decrypt_dataset/banksy_12_encrypted
saved decrypt_dataset/banksy_13_encrypted
saved decrypt_dataset/banksy_14_encrypted
saved decrypt_dataset/banksy_15_encrypted
saved decrypt_dataset/banksy_16_encrypted
saved decrypt_dataset/banksy_17_encrypted
saved decrypt_dataset/banksy_18_encrypted
saved decrypt_dataset/banksy_19_encrypted
saved decrypt_dataset/banksy_20_encrypted
saved decrypt_dataset/banksy_21_encrypted
saved decrypt_dataset/banksy_22_encrypted
saved decrypt_dataset/banksy_23_encrypted
saved decrypt_dataset/banksy_24_encrypted
saved decrypt_dataset/banksy_25_encrypted
saved decrypt_dataset/banksy_26_encrypted
saved decrypt_dataset/banksy_27_encrypted
saved decrypt_dataset/banksy_28_encrypted
saved decrypt_dataset/banksy_29_encrypted
saved decrypt_dataset/banksy_30_encrypted
saved decrypt_dataset/banksy_31_encrypted
Traceback (most recent call last):
  File "/data/scratch/amini/sadhana/2024/crypto-final-project/src/data_generation.py", line 365, in <module>
    gc.collect()
NameError: name 'gc' is not defined
